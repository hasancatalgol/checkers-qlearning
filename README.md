# ğŸ§  Chaser & Runner: Multi-Agent Reinforcement Learning

A simple 8x13 grid-based simulation game with two **chasers (C1, C2)** and one **runner (R)**, where the chasers use **Q-Learning** to learn how to catch the runner. Built with **Python 3.12** and **Pygame**, with modular code organization.

---

## ğŸ“¦ Features

- âœ… Grid-based game environment with visual board
- âœ… Q-Learning for chasers
- âœ… Manual or random runner control
- âœ… RL metrics and telemetry panel (Q-values, actions, episode/step, etc.)
- âœ… Live reward feedback and terminal condition
- âœ… Q-table export after each episode (as JSON)

---

## ğŸ® Game Rules

- Agents move in the order: **Runner â†’ C1 â†’ C2**
- Movement: one cell up/down/left/right or stay
- Black cells are **obstacles**
- **C1/C2 may occupy the same cell**
- The game ends if **R is caught** (i.e. chaser and runner on same cell)

**Scoring per turn:**
- `+2` if distance to R is 1
- `+1` if distance to R is 2
- `âˆ’0.1` penalty otherwise

---

## ğŸ—‚ï¸ File Structure
CHECKERS-QLEARN/
â”‚
â”œâ”€â”€ agents.py # RL agents (Q-learning chasers, random runner)
â”œâ”€â”€ config.py # Constants and display configuration
â”œâ”€â”€ game_ui.py # Drawing grid, agents, info panel
â”œâ”€â”€ main.py # Game loop + integration
â”œâ”€â”€ rules.py # Game logic rules
â”œâ”€â”€ utils.py # Grid math and obstacle definitions
â”œâ”€â”€ assets/ # Button icons and other visuals
â””â”€â”€ requirements.txt # Install dependencies